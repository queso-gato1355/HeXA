{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글과 공백을 제외한 모든 문자를 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='65가갸어어124,asdf,d~!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]','',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'가갸어어'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['단독', '입찰', '보다', '복수', '입찰', '의', '경우']\n"
     ]
    }
   ],
   "source": [
    "print(okt.morphs(u'단독입찰보다 복수입찰의 경우'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['항공기', '체계', '종합', '개발', '경험']\n"
     ]
    }
   ],
   "source": [
    "print(okt.nouns(u'유일하게 항공기 체계 종합개발 경험을 갖고 있는 KAI는'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['날카로운 분석', '날카로운 분석과 신뢰감', '날카로운 분석과 신뢰감 있는 진행', '분석', '신뢰', '진행']\n"
     ]
    }
   ],
   "source": [
    "print(okt.phrases(u'날카로운 분석과 신뢰감 있는 진행으로'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되나욬', 'Noun'), ('ㅋㅋ', 'KoreanParticle')]\n"
     ]
    }
   ],
   "source": [
    "print(okt.pos(u'이것도 되나욬ㅋㅋ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되나요', 'Verb'), ('ㅋㅋ', 'KoreanParticle')]\n"
     ]
    }
   ],
   "source": [
    "print(okt.pos(u'이것도 되나욬ㅋㅋ', norm=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되다', 'Verb'), ('ㅋㅋ', 'KoreanParticle')]\n"
     ]
    }
   ],
   "source": [
    "print(okt.pos(u'이것도 되나욬ㅋㅋ', norm=True, stem=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://konlpy.org/ko/v0.6.0/api/konlpy.tag/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'ㅋㅋㅋㅋㅋ', 'ㅋㅋㅋㅋ', 'ㅋㅋ', 같은 같은 것이 반복되는 것들을 통일시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.normalizer import emoticon_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅋㅋ\n"
     ]
    }
   ],
   "source": [
    "print(emoticon_normalize('ㅋㅋㅋㅋㅋㅋ', num_repeats=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅋㅋ\n"
     ]
    }
   ],
   "source": [
    "print(emoticon_normalize('ㅋㅋㅋㅋ', num_repeats=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "testPath = Path(\"./test.csv\")\n",
    "tidyReviews = [[\"ID\", \"Star\", \"Sum.Polarity\", \"Avg.Polarity\", \"Num.Verb\", \"Num.Adjective\", \"Num.Noun\"]]\n",
    "rootWordDict = list()\n",
    "cache = list()\n",
    "\n",
    "def sentiment(word) -> int:\n",
    "    global cache\n",
    "    jsonPath = Path(\"./SentiWord_info.json\")\n",
    "    with jsonPath.open(encoding = \"UTF-8\") as f:\n",
    "        rootWordDict = json.load(f)\n",
    "    result = 0\n",
    "    for wordcell in cache:\n",
    "        if word == wordcell[\"word\"]:\n",
    "            result = int(wordcell[\"polarity\"])\n",
    "            return result\n",
    "    \n",
    "    for wordcell in rootWordDict:\n",
    "        if word == wordcell[\"word\"]:\n",
    "            result = int(wordcell[\"polarity\"])\n",
    "            if len(cache) < 50: cache.append(wordcell)\n",
    "            else: \n",
    "                cache.pop(0)\n",
    "                cache.append(wordcell)\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def average(top, bottom):\n",
    "    if bottom == 0: return \"N/A\"\n",
    "    return round(top/bottom, 2)\n",
    "\n",
    "\n",
    "with testPath.open(encoding = \"UTF-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    \n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0: continue\n",
    "        buffer = [row[0]]\n",
    "        score = int(re.sub(\"[^0-9]\", '', row[1]))\n",
    "        polarity = 0\n",
    "        verb = 0\n",
    "        adjective = 0\n",
    "        noun = 0\n",
    "        buffer.append(score)\n",
    "        singleReview = okt.pos(emoticon_normalize(row[2], num_repeats=1), norm = True, stem = True)\n",
    "        lengthOfSingleReview = len(singleReview)\n",
    "        for word, part in singleReview:\n",
    "            if part == \"Noun\": noun += 1\n",
    "            elif part == \"Verb\": verb += 1\n",
    "            elif part == \"Adjective\": adjective += 1\n",
    "            else: continue\n",
    "            if sentiment(word) == 0: \n",
    "                if part == \"Noun\": noun -= 1\n",
    "                elif part == \"Verb\": verb -= 1\n",
    "                elif part == \"Adjective\": adjective -= 1\n",
    "                continue\n",
    "            polarity += sentiment(word)\n",
    "        if verb+adjective+noun == 0: continue\n",
    "        buffer += [polarity, average(polarity, verb+adjective+noun), verb, adjective, noun]\n",
    "        tidyReviews.append(buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"review.csv\", 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(tidyReviews)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
